{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPefnvSEMPITI42Mp8uHssg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yukselendincer/Aygaz_Ai/blob/main/FashionMinst.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y720MeOwHNZk"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as kr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "data= fashion_mnist.load_data()\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = data\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "X_train = train_images\n",
        "X_test = test_images\n",
        "y_train = train_labels\n",
        "y_test = test_labels\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n"
      ]
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fashion MNIST veri setini yükleyelim\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Bölünmüş verilerin boyutlarını yazdıralım\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# Veri seti içindeki görüntülerin boyutlarını yazdıralım\n",
        "image_shape = X_train[0].shape\n",
        "print(f\"Image shape: {image_shape}\")\n",
        "\n",
        "# İlk 10 görüntüyü görselleştirelim\n",
        "fig, axes = plt.subplots(1, 30, figsize=(20, 2))\n",
        "for i in range(30):\n",
        "    axes[i].imshow(X_train[i], cmap='gray')\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Verileri normalize edelim\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Normalizasyon sonrası örnek bir görüntüyü görselleştirelim\n",
        "plt.imshow(X_train[0], cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "A3k3CGpOHkwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Verilerin Hazırlanması\n",
        "Öncelikle veriler yüklenir, yeniden şekillendirilir ve normalize edilir:\n",
        "\n",
        "Veri Yükleme: fashion_mnist.load_data() fonksiyonu, eğitim ve test veri setlerini yükler.\n",
        "Veri Yeniden Şekillendirme ve Normalizasyon: Görüntüler 28x28 piksel boyutundadır. Bu yüzden, her bir görüntü 784 (28*28) boyutunda bir vektöre dönüştürülür. Piksel değerleri [0, 255] aralığında olduğundan, bu değerler 255’e bölünerek [0, 1] aralığına normalize edilir.\n",
        "2. Veri Bölme ve Standardizasyon\n",
        "Veriler eğitim ve doğrulama setlerine bölünür:\n",
        "\n",
        "Veri Bölme: Eğitim verileri, eğitim ve doğrulama setleri olarak train_test_split fonksiyonu ile bölünür.\n",
        "Standardizasyon: StandardScaler kullanılarak veriler standardize edilir. Bu, özelliklerin ortalamasının 0 ve standart sapmasının 1 olmasını sağlar.\n",
        "3. Model Eğitimi ve Değerlendirme\n",
        "Her bir makine öğrenmesi algoritması için model eğitimi ve değerlendirmesi aşağıdaki şekilde gerçekleştirilir:\n",
        "\n",
        "a. K-Nearest Neighbors (KNN)\n",
        "Model Tanımı: KNeighborsClassifier\n",
        "Eğitim: model.fit(X_train, y_train)\n",
        "Tahmin: model.predict(X_val)\n",
        "Değerlendirme: accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "b. Support Vector Machine (SVM)\n",
        "Model Tanımı: SVC\n",
        "Eğitim ve Değerlendirme: Aynı yöntemler KNN ile kullanılır.\n",
        "c. Logistic Regression\n",
        "Model Tanımı: LogisticRegression\n",
        "Eğitim ve Değerlendirme: Aynı yöntemler KNN ile kullanılır.\n",
        "d. Decision Tree\n",
        "Model Tanımı: DecisionTreeClassifier\n",
        "Eğitim ve Değerlendirme: Aynı yöntemler KNN ile kullanılır.\n",
        "e. Random Forest\n",
        "Model Tanımı: RandomForestClassifier\n",
        "Eğitim ve Değerlendirme: Aynı yöntemler KNN ile kullanılır.\n",
        "f. Gradient Boosting Machine (GBM)\n",
        "Model Tanımı: GradientBoostingClassifier\n",
        "Eğitim ve Değerlendirme: Aynı yöntemler KNN ile kullanılır.\n",
        "g. LightGBM\n",
        "Model Tanımı: lgb.LGBMClassifier\n",
        "Eğitim ve Değerlendirme: Aynı yöntemler KNN ile kullanılır.\n",
        "h. XGBoost\n",
        "Model Tanımı: xgb.XGBClassifier\n",
        "Eğitim ve Değerlendirme: Aynı yöntemler KNN ile kullanılır.\n",
        "i. CatBoost\n",
        "Model Tanımı: CatBoostClassifier\n",
        "Eğitim ve Değerlendirme: Aynı yöntemler KNN ile kullanılır.\n",
        "4. Derin Öğrenme\n",
        "Model Tanımı: Keras kullanılarak basit bir yapay sinir ağı (YSA) modeli tanımlanır.\n",
        "Katmanlar: 128 nöronlu giriş katmanı, 64 nöronlu gizli katman ve 10 sınıflı çıkış katmanı.\n",
        "Eğitim: model.fit()\n",
        "Tahmin: model.predict()\n",
        "Değerlendirme: accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
      ],
      "metadata": {
        "id": "uWjSe9UjKY1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "import tensorflow as tf\n",
        "\n",
        "# Verileri yeniden şekillendirelim ve normalize edelim\n",
        "X_train = X_train.reshape(-1, 28*28) / 255.0\n",
        "X_test = X_test.reshape(-1, 28*28) / 255.0\n",
        "\n",
        "# Eğitim ve test setlerini bölme\n",
        "X_train_part, X_val, y_train_part, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Veri standardizasyonu\n",
        "scaler = StandardScaler()\n",
        "X_train_part = scaler.fit_transform(X_train_part)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Modelleri tanımlama ve eğitme fonksiyonu\n",
        "def train_and_evaluate(model, X_train, y_train, X_val, y_val):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    precision = precision_score(y_val, y_pred, average='weighted')\n",
        "    recall = recall_score(y_val, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "    print(f\"Model: {model.__class__.__name__}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(classification_report(y_val, y_pred))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# KNN\n",
        "knn = KNeighborsClassifier()\n",
        "train_and_evaluate(knn, X_train_part, y_train_part, X_val, y_val)\n",
        "\n",
        "# SVM\n",
        "svm = SVC()\n",
        "train_and_evaluate(svm, X_train_part, y_train_part, X_val, y_val)\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "train_and_evaluate(lr, X_train_part, y_train_part, X_val, y_val)\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier()\n",
        "train_and_evaluate(dt, X_train_part, y_train_part, X_val, y_val)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "train_and_evaluate(rf, X_train_part, y_train_part, X_val, y_val)\n",
        "\n",
        "# Gradient Boosting Machine (GBM)\n",
        "gbm = GradientBoostingClassifier()\n",
        "train_and_evaluate(gbm, X_train_part, y_train_part, X_val, y_val)\n",
        "\n",
        "# LightGBM\n",
        "lgbm = lgb.LGBMClassifier()\n",
        "train_and_evaluate(lgbm, X_train_part, y_train_part, X_val, y_val)\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "train_and_evaluate(xgb_model, X_train_part, y_train_part, X_val, y_val)\n",
        "\n",
        "# CatBoost\n",
        "catboost_model = CatBoostClassifier(verbose=0)\n",
        "train_and_evaluate(catboost_model, X_train_part, y_train_part, X_val, y_val)\n",
        "\n",
        "# Derin Öğrenme - Basit Yapay Sinir Ağı\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_part, y_train_part, epochs=10, validation_data=(X_val, y_val), verbose=2)\n",
        "\n",
        "# Modelin değerlendirilmesi\n",
        "y_pred_dl = np.argmax(model.predict(X_val), axis=1)\n",
        "accuracy_dl = accuracy_score(y_val, y_pred_dl)\n",
        "precision_dl = precision_score(y_val, y_pred_dl, average='weighted')\n",
        "recall_dl = recall_score(y_val, y_pred_dl, average='weighted')\n",
        "f1_dl = f1_score(y_val, y_pred_dl, average='weighted')\n",
        "print(f\"Deep Learning Model\")\n",
        "print(f\"Accuracy: {accuracy_dl:.4f}\")\n",
        "print(f\"Precision: {precision_dl:.4f}\")\n",
        "print(f\"Recall: {recall_dl:.4f}\")\n",
        "print(f\"F1 Score: {f1_dl:.4f}\")\n",
        "print(classification_report(y_val, y_pred_dl))\n"
      ],
      "metadata": {
        "id": "y9-yDxIKJ2Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Değerlendirme Metrikleri**\n",
        "Accuracy: Doğru tahmin edilen örneklerin toplam örnek sayısına oranı.\n",
        "Precision: Doğru pozitif tahminlerin toplam pozitif tahminlere oranı.\n",
        "Recall: Doğru pozitif tahminlerin toplam gerçek pozitiflere oranı.\n",
        "F1-Score: Precision ve Recall’un harmonik ortalaması.\n",
        "ROC AUC: ROC eğrisi altındaki alan (Modelin ayırt edicilik gücünü gösterir)."
      ],
      "metadata": {
        "id": "IEgsCcTRK0Ym"
      }
    }
  ]
}